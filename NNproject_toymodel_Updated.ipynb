{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"lGMtkLoxpJFx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9K8ClOZJrIy3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"14f7b8a0-822a-482f-a12c-bdd97b9912ca","executionInfo":{"status":"ok","timestamp":1682888406179,"user_tz":240,"elapsed":1285,"user":{"displayName":"Peiqi Chen","userId":"03415428070926034476"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# Loading dataset "],"metadata":{"id":"ek5ovpm6RtxP"}},{"cell_type":"markdown","source":["# Dense model"],"metadata":{"id":"x0iAXLGSB8nl"}},{"cell_type":"code","source":[],"metadata":{"id":"7BkE-64S9jQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"MUe_JJzDBi6-","executionInfo":{"status":"error","timestamp":1682889410906,"user_tz":240,"elapsed":412,"user":{"displayName":"Peiqi Chen","userId":"03415428070926034476"}},"outputId":"87a1436a-f5d4-43b0-b747-e9b344350f04"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-847740f0eb97>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidation_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_image_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m history = model.fit(\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_image_paths' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"fgpGBOiYBi9D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pZaG7WUtBi_N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NFe3N2L7BjBQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_K0sFECpBjDb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"A1TD8cS9BjFl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XkCFn-d4BjHf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras import layers, models\n","\n","def func(path, label):\n","    frame = cv2.imread(path)\n","\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    blur = cv2.GaussianBlur(gray, (5, 5), 2)\n","    thresh = cv2.adaptiveThreshold(blur, 255, 1, 1, 11, 2)\n","\n","    return thresh, label\n","# Define the image dimensions and batch size\n","image_width, image_height = 200, 200\n","batch_size = 32\n","\n","# Specify the paths to the directories\n","train_dir = '/content/drive/Shareddrives/BA865 - Team Project/Image_dataset/train'\n","validation_dir = '/content/drive/Shareddrives/BA865 - Team Project/Image_dataset/validation'\n","\n","# Create an ImageDataGenerator for data augmentation and rescaling\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Load the training and validation data from the directories\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(image_width, image_height),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    validation_dir,\n","    target_size=(image_width, image_height),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Oqc4s6u5HOt","outputId":"89ecf92e-e2c7-4f10-ddd8-b6b8a1f5661f","executionInfo":{"status":"ok","timestamp":1682888425390,"user_tz":240,"elapsed":7509,"user":{"displayName":"Peiqi Chen","userId":"03415428070926034476"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 84 images belonging to 34 classes.\n","Found 34 images belonging to 34 classes.\n"]}]},{"cell_type":"code","source":["# Create the model\n","model = models.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(220, 220, 3)),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(\n","    train_generator,\n","    epochs=10,\n","    validation_data=validation_generator\n",")\n","\n","# Evaluate the model\n","scores = model.evaluate(validation_dataset)\n","print(f\"Validation accuracy: {scores[1]*100:.2f}%\")\n"],"metadata":{"id":"8n2SoyZF6IbC","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"e0255aba-aaf0-4c67-bca2-62897273767f","executionInfo":{"status":"error","timestamp":1682889002607,"user_tz":240,"elapsed":3812,"user":{"displayName":"Peiqi Chen","userId":"03415428070926034476"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-98561bf2fa90>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_2/dense_4/Relu' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-5-98561bf2fa90>\", line 18, in <cell line: 18>\n      history = model.fit(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/core/dense.py\", line 255, in call\n      outputs = self.activation(outputs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5396, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_2/dense_4/Relu'\nMatrix size-incompatible: In[0]: [20,67712], In[1]: [80000,128]\n\t [[{{node sequential_2/dense_4/Relu}}]] [Op:__inference_train_function_4648]"]}]},{"cell_type":"markdown","source":["## Prediction on testset "],"metadata":{"id":"6w-H-WgWRyJW"}},{"cell_type":"code","source":["import os\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","import numpy as np\n","\n","def predict_single_image(model, image_path, target_size, class_labels):\n","    image = load_img(image_path, target_size=target_size)\n","    image_array = img_to_array(image)\n","    image_array = np.expand_dims(image_array, axis=0)\n","    prediction = model.predict(image_array)\n","    predicted_class_index = np.argmax(prediction, axis=-1)[0]\n","    predicted_class_label = class_labels[predicted_class_index]\n","    return predicted_class_label\n","\n","def predict_multiple_images(model, folder_path, class_labels, target_size=(200, 200)):\n","    predicted_labels = {}\n","    for root, dirs, files in os.walk(folder_path):\n","        for image_filename in files:\n","            # Construct the full path to the image file\n","            image_path = os.path.join(root, image_filename)\n","            if os.path.isfile(image_path):  # Ensure that the item is a file\n","                predicted_class_label = predict_single_image(model, image_path, target_size, class_labels)\n","                predicted_labels[image_filename] = predicted_class_label\n","    return predicted_labels\n","\n","# Define the path to the folder containing the test images\n","test_dir = '/content/drive/Shareddrives/BA865 - Team Project/Image_dataset/test'\n","\n","# Get the class labels from the training generator\n","class_labels = list(train_generator.class_indices.keys())\n","\n","# Use the trained model to predict the classes of the test images\n","predicted_labels = predict_multiple_images(model, test_dir, class_labels)\n","print('Predicted class labels for test images:')\n","for image_filename, predicted_class_label in predicted_labels.items():\n","    print(f'{image_filename}: {predicted_class_label}')\n"],"metadata":{"id":"xFMiEGjGP8PO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Conv2 model"],"metadata":{"id":"o664Pzo8Ig17"}},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n","\n","# Define the CNN model\n","model = Sequential([\n","    # Convolutional layer with 32 filters, each with size 3x3, and ReLU activation\n","    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(200, 200, 3)),\n","    # Max pooling layer with pool size 2x2\n","    MaxPooling2D(pool_size=(2, 2)),\n","    # Dropout layer with 25% dropout rate\n","    Dropout(0.25),\n","    # Another convolutional layer with 64 filters, each with size 3x3, and ReLU activation\n","    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n","    # Max pooling layer with pool size 2x2\n","    MaxPooling2D(pool_size=(2, 2)),\n","    # Dropout layer with 25% dropout rate\n","    Dropout(0.25),\n","    # Flatten layer to convert 3D feature maps to 1D feature vectors\n","    Flatten(),\n","    # Dense layer with 128 neurons and ReLU activation\n","    Dense(128, activation='relu'),\n","    # Dropout layer with 50% dropout rate\n","    Dropout(0.5),\n","    # Output layer with the number of neurons equal to the number of classes, using softmax activation\n","    Dense(len(train_generator.class_indices), activation='softmax')  # num_classes should be replaced with the actual number of classes\n","])\n"],"metadata":{"id":"4oX3kQRwJFKu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Print a summary of the model architecture\n","model.summary()\n"],"metadata":{"id":"ZjmL9xdYKwzD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Train the model (replace train_generator and validation_generator with your actual generators)\n","history = model.fit(\n","    train_generator,\n","    epochs=10,\n","    validation_data=validation_generator\n",")\n"],"metadata":{"id":"CxLKz86PK0fR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Evaluate the model on the validation data\n","scores = model.evaluate(validation_generator)\n","print(f\"Validation accuracy: {scores[1]*100:.2f}%\")\n"],"metadata":{"id":"HfqyUqG6Kqto"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prediction on testset"],"metadata":{"id":"-5b0x8p8R5Du"}},{"cell_type":"code","source":["import os\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","import numpy as np\n","\n","def predict_single_image(model, image_path, target_size, class_labels):\n","    image = load_img(image_path, target_size=target_size)\n","    image_array = img_to_array(image)\n","    image_array = np.expand_dims(image_array, axis=0)\n","    prediction = model.predict(image_array)\n","    predicted_class_index = np.argmax(prediction, axis=-1)[0]\n","    predicted_class_label = class_labels[predicted_class_index]\n","    return predicted_class_label\n","\n","def predict_multiple_images(model, folder_path, class_labels, target_size=(200, 200)):\n","    predicted_labels = {}\n","    for root, dirs, files in os.walk(folder_path):\n","        for image_filename in files:\n","            # Construct the full path to the image file\n","            image_path = os.path.join(root, image_filename)\n","            if os.path.isfile(image_path):  # Ensure that the item is a file\n","                predicted_class_label = predict_single_image(model, image_path, target_size, class_labels)\n","                predicted_labels[image_filename] = predicted_class_label\n","    return predicted_labels\n","\n","# Define the path to the folder containing the test images\n","test_dir = '/content/drive/Shareddrives/BA865 - Team Project/Image_dataset/test'\n","\n","# Get the class labels from the training generator (replace train_generator with your actual generator)\n","class_labels = list(train_generator.class_indices.keys())\n","\n"],"metadata":{"id":"Qr5-he6aPMHa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use the trained model to predict the classes of the test images\n","predicted_labels = predict_multiple_images(model, test_dir, class_labels)\n","print('Predicted class labels for test images:')\n","for image_filename, predicted_class_label in predicted_labels.items():\n","    print(f'{image_filename}: {predicted_class_label}')"],"metadata":{"id":"mfv0MI4dPQkk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4BQB2yXGpjdN"},"execution_count":null,"outputs":[]}]}